{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClothingGAN-Demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "Kj8mGkmH0xgA",
        "outputId": "485b5a56-4a6c-4b43-f328-2e9b68caa333"
      },
      "source": [
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 200})'''))\n",
        "!pip install ninja gradio fbpca boto3 requests==2.23.0 urllib3==1.25.11"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 200})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (1.10.2.3)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.7/dist-packages (2.4.6)\n",
            "Requirement already satisfied: fbpca in /usr/local/lib/python3.7/dist-packages (1.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.20.20)\n",
            "Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3==1.25.11 in /usr/local/lib/python3.7/dist-packages (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (3.0.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.5)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from gradio) (3.12.0)\n",
            "Requirement already satisfied: Flask>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.4)\n",
            "Requirement already satisfied: flask-cachebuster in /usr/local/lib/python3.7/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: Flask-Login in /usr/local/lib/python3.7/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: Flask-Cors>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from gradio) (3.0.10)\n",
            "Requirement already satisfied: analytics-python in /usr/local/lib/python3.7/dist-packages (from gradio) (1.4.0)\n",
            "Requirement already satisfied: paramiko in /usr/local/lib/python3.7/dist-packages (from gradio) (2.8.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.7/dist-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.19.5)\n",
            "Requirement already satisfied: markdown2 in /usr/local/lib/python3.7/dist-packages (from gradio) (2.4.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (1.0.1)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from Flask-Cors>=3.0.8->gradio) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.1->gradio) (2.0.1)\n",
            "Requirement already satisfied: botocore<1.24.0,>=1.23.20 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.23.20)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.5.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.20->boto3) (2.8.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.6)\n",
            "Requirement already satisfied: backoff==1.10.0 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.10.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2018.9)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (3.2.0)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (1.4.0)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (36.0.0)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwf-gggHtA_t",
        "outputId": "481bdfb5-26d4-4236-ef95-0d10543bd841"
      },
      "source": [
        "!git clone https://github.com/JoelJJoseph/fashion.git\n",
        "%cd ClothingGAN/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fashion'...\n",
            "remote: Enumerating objects: 202, done.\u001b[K\n",
            "remote: Counting objects: 100% (202/202), done.\u001b[K\n",
            "remote: Compressing objects: 100% (197/197), done.\u001b[K\n",
            "remote: Total 202 (delta 15), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (202/202), 54.94 MiB | 12.57 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "[Errno 2] No such file or directory: 'ClothingGAN/'\n",
            "/content/ClothingGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "2BYsIETVtGnF",
        "outputId": "98ad6001-9e30-4866-fe2b-ccfc882492f2"
      },
      "source": [
        "from IPython.display import Javascript\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 200})'''))\n",
        "!git submodule update --init --recursive\n",
        "!python -c \"import nltk; nltk.download('wordnet')\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 200})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJg91yvSwKi3"
      },
      "source": [
        "selected_model = 'lookbook'\n",
        "\n",
        "# Load model\n",
        "from IPython.utils import io\n",
        "import torch\n",
        "import PIL\n",
        "import numpy as np\n",
        "import ipywidgets as widgets\n",
        "from PIL import Image\n",
        "import imageio\n",
        "from models import get_instrumented_model\n",
        "from decomposition import get_or_compute\n",
        "from config import Config\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "# Speed up computation\n",
        "torch.autograd.set_grad_enabled(False)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Specify model to use\n",
        "config = Config(\n",
        "  model='StyleGAN2',\n",
        "  layer='style',\n",
        "  output_class=selected_model,\n",
        "  components=80,\n",
        "  use_w=True,\n",
        "  batch_size=5_000, # style layer quite small\n",
        ")\n",
        "\n",
        "inst = get_instrumented_model(config.model, config.output_class,\n",
        "                              config.layer, torch.device('cuda'), use_w=config.use_w)\n",
        "\n",
        "path_to_components = get_or_compute(config, inst)\n",
        "\n",
        "model = inst.model\n",
        "\n",
        "comps = np.load(path_to_components)\n",
        "lst = comps.files\n",
        "latent_dirs = []\n",
        "latent_stdevs = []\n",
        "\n",
        "load_activations = False\n",
        "\n",
        "for item in lst:\n",
        "    if load_activations:\n",
        "      if item == 'act_comp':\n",
        "        for i in range(comps[item].shape[0]):\n",
        "          latent_dirs.append(comps[item][i])\n",
        "      if item == 'act_stdev':\n",
        "        for i in range(comps[item].shape[0]):\n",
        "          latent_stdevs.append(comps[item][i])\n",
        "    else:\n",
        "      if item == 'lat_comp':\n",
        "        for i in range(comps[item].shape[0]):\n",
        "          latent_dirs.append(comps[item][i])\n",
        "      if item == 'lat_stdev':\n",
        "        for i in range(comps[item].shape[0]):\n",
        "          latent_stdevs.append(comps[item][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCR_3Ghos2kK"
      },
      "source": [
        "from ipywidgets import fixed\n",
        "\n",
        "def log_progress(sequence, every=1, size=None, name='Items'):\n",
        "    from ipywidgets import IntProgress, HTML, VBox\n",
        "    from IPython.display import display\n",
        "\n",
        "    is_iterator = False\n",
        "    if size is None:\n",
        "        try:\n",
        "            size = len(sequence)\n",
        "        except TypeError:\n",
        "            is_iterator = True\n",
        "    if size is not None:\n",
        "        if every is None:\n",
        "            if size <= 200:\n",
        "                every = 1\n",
        "            else:\n",
        "                every = int(size / 200)     # every 0.5%\n",
        "    else:\n",
        "        assert every is not None, 'sequence is iterator, set every'\n",
        "\n",
        "    if is_iterator:\n",
        "        progress = IntProgress(min=0, max=1, value=1)\n",
        "        progress.bar_style = 'info'\n",
        "    else:\n",
        "        progress = IntProgress(min=0, max=size, value=0)\n",
        "    label = HTML()\n",
        "    box = VBox(children=[label, progress])\n",
        "    display(box)\n",
        "\n",
        "    index = 0\n",
        "    try:\n",
        "        for index, record in enumerate(sequence, 1):\n",
        "            if index == 1 or index % every == 0:\n",
        "                if is_iterator:\n",
        "                    label.value = '{name}: {index} / ?'.format(\n",
        "                        name=name,\n",
        "                        index=index\n",
        "                    )\n",
        "                else:\n",
        "                    progress.value = index\n",
        "                    label.value = u'{name}: {index} / {size}'.format(\n",
        "                        name=name,\n",
        "                        index=index,\n",
        "                        size=size\n",
        "                    )\n",
        "            yield record\n",
        "    except:\n",
        "        progress.bar_style = 'danger'\n",
        "        raise\n",
        "    else:\n",
        "        progress.bar_style = 'success'\n",
        "        progress.value = index\n",
        "        label.value = \"{name}: {index}\".format(\n",
        "            name=name,\n",
        "            index=str(index or '?')\n",
        "        )\n",
        "\n",
        "def name_direction(sender):\n",
        "  if not text.value:\n",
        "    print('Please name the direction before saving')\n",
        "    return\n",
        "    \n",
        "  if num in named_directions.values():\n",
        "    target_key = list(named_directions.keys())[list(named_directions.values()).index(num)]\n",
        "    print(f'Direction already named: {target_key}')\n",
        "    print(f'Overwriting... ')\n",
        "    del(named_directions[target_key])\n",
        "  named_directions[text.value] = [num, start_layer.value, end_layer.value]\n",
        "  save_direction(random_dir, text.value)\n",
        "  for item in named_directions:\n",
        "    print(item, named_directions[item])\n",
        "\n",
        "def save_direction(direction, filename):\n",
        "  filename += \".npy\"\n",
        "  np.save(filename, direction, allow_pickle=True, fix_imports=True)\n",
        "  print(f'Latent direction saved as {filename}')\n",
        "\n",
        "def mix_w(w1, w2, content, style):\n",
        "    for i in range(0,5):\n",
        "        w2[i] = w1[i] * (1 - content) + w2[i] * content\n",
        "\n",
        "    for i in range(5, 16):\n",
        "        w2[i] = w1[i] * (1 - style) + w2[i] * style\n",
        "    \n",
        "    return w2\n",
        "\n",
        "def display_sample_pytorch(seed, truncation, directions, distances, scale, start, end, w=None, disp=True, save=None, noise_spec=None):\n",
        "    # blockPrint()\n",
        "    model.truncation = truncation\n",
        "    if w is None:\n",
        "        w = model.sample_latent(1, seed=seed).detach().cpu().numpy()\n",
        "        w = [w]*model.get_max_latents() # one per layer\n",
        "    else:\n",
        "        w = [np.expand_dims(x, 0) for x in w]\n",
        "    \n",
        "    for l in range(start, end):\n",
        "      for i in range(len(directions)):\n",
        "        w[l] = w[l] + directions[i] * distances[i] * scale\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "    #save image and display\n",
        "    out = model.sample_np(w)\n",
        "    final_im = Image.fromarray((out * 255).astype(np.uint8)).resize((500,500),Image.LANCZOS)\n",
        "    \n",
        "    \n",
        "    if save is not None:\n",
        "      if disp == False:\n",
        "        print(save)\n",
        "      final_im.save(f'out/{seed}_{save:05}.png')\n",
        "    if disp:\n",
        "      display(final_im)\n",
        "    \n",
        "    return final_im\n",
        "\n",
        "def generate_mov(seed, truncation, direction_vec, scale, layers, n_frames, out_name = 'out', noise_spec = None, loop=True):\n",
        "  \"\"\"Generates a mov moving back and forth along the chosen direction vector\"\"\"\n",
        "  # Example of reading a generated set of images, and storing as MP4.\n",
        "  %mkdir out\n",
        "  movieName = f'out/{out_name}.mp4'\n",
        "  offset = -10\n",
        "  step = 20 / n_frames\n",
        "  imgs = []\n",
        "  for i in log_progress(range(n_frames), name = \"Generating frames\"):\n",
        "    print(f'\\r{i} / {n_frames}', end='')\n",
        "    w = model.sample_latent(1, seed=seed).cpu().numpy()\n",
        "\n",
        "    model.truncation = truncation\n",
        "    w = [w]*model.get_max_latents() # one per layer\n",
        "    for l in layers:\n",
        "      if l <= model.get_max_latents():\n",
        "          w[l] = w[l] + direction_vec * offset * scale\n",
        "\n",
        "    #save image and display\n",
        "    out = model.sample_np(w)\n",
        "    final_im = Image.fromarray((out * 255).astype(np.uint8))\n",
        "    imgs.append(out)\n",
        "    #increase offset\n",
        "    offset += step\n",
        "  if loop:\n",
        "    imgs += imgs[::-1]\n",
        "  with imageio.get_writer(movieName, mode='I') as writer:\n",
        "    for image in log_progress(list(imgs), name = \"Creating animation\"):\n",
        "        writer.append_data(img_as_ubyte(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jneXxZnNwHo5"
      },
      "source": [
        "from gradio import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "def generate_image(seed1, seed2, content, style, truncation, c0, c1, c2, c3, c4, c5, c6, start_layer, end_layer):\n",
        "    seed1 = int(seed1)\n",
        "    seed2 = int(seed2)\n",
        "\n",
        "    scale = 1\n",
        "    params = {'c0': c0,\n",
        "          'c1': c1,\n",
        "          'c2': c2,\n",
        "          'c3': c3,\n",
        "          'c4': c4,\n",
        "          'c5': c5,\n",
        "          'c6': c6}\n",
        "\n",
        "    param_indexes = {'c0': 0,\n",
        "              'c1': 1,\n",
        "              'c2': 2,\n",
        "              'c3': 3,\n",
        "              'c4': 4,\n",
        "              'c5': 5,\n",
        "              'c6': 6}\n",
        "\n",
        "    directions = []\n",
        "    distances = []\n",
        "    for k, v in params.items():\n",
        "        directions.append(latent_dirs[param_indexes[k]])\n",
        "        distances.append(v)\n",
        "\n",
        "    w1 = model.sample_latent(1, seed=seed1).detach().cpu().numpy()\n",
        "    w1 = [w1]*model.get_max_latents() # one per layer\n",
        "    im1 = model.sample_np(w1)\n",
        "\n",
        "    w2 = model.sample_latent(1, seed=seed2).detach().cpu().numpy()\n",
        "    w2 = [w2]*model.get_max_latents() # one per layer\n",
        "    im2 = model.sample_np(w2)\n",
        "    combined_im = np.concatenate([im1, im2], axis=1)\n",
        "    input_im = Image.fromarray((combined_im * 255).astype(np.uint8))\n",
        "    \n",
        "\n",
        "    mixed_w = mix_w(w1, w2, content, style)\n",
        "    return input_im, display_sample_pytorch(seed1, truncation, directions, distances, scale, int(start_layer), int(end_layer), w=mixed_w, disp=False)\n",
        "\n",
        "truncation = gr.inputs.Slider(minimum=0, maximum=1, default=0.5, label=\"Truncation\")\n",
        "start_layer = gr.inputs.Number(default=0, label=\"Start Layer\")\n",
        "end_layer = gr.inputs.Number(default=14, label=\"End Layer\")\n",
        "seed1 = gr.inputs.Number(default=0, label=\"Seed 1\")\n",
        "seed2 = gr.inputs.Number(default=0, label=\"Seed 2\")\n",
        "content = gr.inputs.Slider(label=\"Structure\", minimum=0, maximum=1, default=0.5)\n",
        "style = gr.inputs.Slider(label=\"Style\", minimum=0, maximum=1, default=0.5)\n",
        "\n",
        "slider_max_val = 20\n",
        "slider_min_val = -20\n",
        "slider_step = 1\n",
        "\n",
        "c0 = gr.inputs.Slider(label=\"Sleeve & Size\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "c1 = gr.inputs.Slider(label=\"Dress - Jacket\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "c2 = gr.inputs.Slider(label=\"Female Coat\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "c3 = gr.inputs.Slider(label=\"Coat\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "c4 = gr.inputs.Slider(label=\"Graphics\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "c5 = gr.inputs.Slider(label=\"Dark\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "c6 = gr.inputs.Slider(label=\"Less Cleavage\", minimum=slider_min_val, maximum=slider_max_val, default=0)\n",
        "\n",
        "\n",
        "scale = 1\n",
        "\n",
        "inputs = [seed1, seed2, content, style, truncation, c0, c1, c2, c3, c4, c5, c6, start_layer, end_layer]\n",
        "\n",
        "gr.Interface(generate_image, inputs, [\"image\", \"image\"], live=True, title=\"ClothingGAN\").launch()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}